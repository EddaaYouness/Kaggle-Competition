{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport random\nplt.style.use(\"fivethirtyeight\")\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-27T14:27:41.771325Z","iopub.execute_input":"2022-04-27T14:27:41.771831Z","iopub.status.idle":"2022-04-27T14:27:42.757581Z","shell.execute_reply.started":"2022-04-27T14:27:41.771740Z","shell.execute_reply":"2022-04-27T14:27:42.756724Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/song-popularity-prediction/train.csv')\ntest = pd.read_csv('../input/song-popularity-prediction/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:27:54.130696Z","iopub.execute_input":"2022-04-27T14:27:54.131003Z","iopub.status.idle":"2022-04-27T14:27:54.273831Z","shell.execute_reply.started":"2022-04-27T14:27:54.130968Z","shell.execute_reply":"2022-04-27T14:27:54.273025Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:27:54.929431Z","iopub.execute_input":"2022-04-27T14:27:54.929978Z","iopub.status.idle":"2022-04-27T14:27:54.957541Z","shell.execute_reply.started":"2022-04-27T14:27:54.929930Z","shell.execute_reply":"2022-04-27T14:27:54.956481Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:27:56.339096Z","iopub.execute_input":"2022-04-27T14:27:56.339403Z","iopub.status.idle":"2022-04-27T14:27:56.364756Z","shell.execute_reply.started":"2022-04-27T14:27:56.339368Z","shell.execute_reply":"2022-04-27T14:27:56.363893Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:27:57.208792Z","iopub.execute_input":"2022-04-27T14:27:57.209355Z","iopub.status.idle":"2022-04-27T14:27:57.282533Z","shell.execute_reply.started":"2022-04-27T14:27:57.209317Z","shell.execute_reply":"2022-04-27T14:27:57.281587Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Missing Values ","metadata":{}},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:27:58.757739Z","iopub.execute_input":"2022-04-27T14:27:58.758063Z","iopub.status.idle":"2022-04-27T14:27:58.768795Z","shell.execute_reply.started":"2022-04-27T14:27:58.758027Z","shell.execute_reply":"2022-04-27T14:27:58.767889Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(18,16))\nsns.displot(\n    data=train.isna().melt(value_name=\"missing\"),\n    y=\"variable\",\n    hue=\"missing\",\n    multiple=\"fill\",\n    aspect=3,\n    palette='copper' \n)\nplt.title('Bar plot showing Non-Missing Values in Train data', weight = 'bold', size = 20, color = 'blue')\nplt.xlabel(\" Percentage \")\nplt.ylabel(\" Columns \")\nplt.xticks(size = 12, weight = 'bold', color = 'maroon')\nplt.yticks(size = 12, weight = 'bold', color = 'maroon');\n\nplt.figure(figsize=(18,16))\nsns.displot(\n    data=test.isna().melt(value_name=\"missing\"),\n    y=\"variable\",\n    hue=\"missing\",\n    multiple=\"fill\",\n    aspect=3,\n    palette='copper' \n)\nplt.title('Bar plot showing Non-Missing Values in Train data', weight = 'bold', size = 20, color = 'blue')\nplt.xlabel(\" Percentage \")\nplt.ylabel(\" Columns \")\nplt.xticks(size = 12, weight = 'bold', color = 'maroon')\nplt.yticks(size = 12, weight = 'bold', color = 'maroon');","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:27:59.550676Z","iopub.execute_input":"2022-04-27T14:27:59.551515Z","iopub.status.idle":"2022-04-27T14:28:02.051346Z","shell.execute_reply.started":"2022-04-27T14:27:59.551458Z","shell.execute_reply":"2022-04-27T14:28:02.050391Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Feature With Missing Values : 8 Columns\n- song_duration_ms\n- acousticness\n- danceability \n- energy\n- instrumentalness \n- key\n- liveness \n- loudness","metadata":{}},{"cell_type":"code","source":"useful_cols = [col for col in train.columns if col not in ['id', 'song_popularity']]\ncols_dist = [col for col in useful_cols if col not in ['key', 'audio_mode', 'time_signature']]\ncolor_ = [ '#9D2417', '#AF41B4', '#003389' ,'#3C5F41',  '#967032', '#2734DE'] \ncmap_ = ['magma', 'copper', 'crest']\n\n\nplt.figure(figsize= (16,18))\nfor i,col in enumerate(train[useful_cols].columns):\n    rand_col = color_[random.sample(range(6), 1)[0]]\n    plt.subplot(5,3, i+1)\n    if col in cols_dist:\n        \n        sns.kdeplot(train[col], color = rand_col, fill = rand_col )\n        plt.title(col,weight = 'bold', color = rand_col)\n        plt.ylabel(\" \")\n        plt.xlabel(\" \")\n        plt.tight_layout()\n    else:\n        sns.countplot(data = train , x = col, palette = cmap_[random.sample(range(3), 1)[0]] )\n        plt.title(col,weight = 'bold', color = 'black')\n        plt.ylabel(\" \")\n        plt.xlabel(\" \")\n        plt.tight_layout()\n        \nplt.subplot(5,3, 14)\nsns.kdeplot(np.log(train['instrumentalness']), color = rand_col, fill = rand_col )\nplt.title('instrumentalness (log transformed)',weight = 'bold', color = rand_col, size = 17)\nplt.ylabel(\" \")\nplt.xlabel(\" \")\nplt.tight_layout()\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:28:03.381241Z","iopub.execute_input":"2022-04-27T14:28:03.381513Z","iopub.status.idle":"2022-04-27T14:28:09.290723Z","shell.execute_reply.started":"2022-04-27T14:28:03.381484Z","shell.execute_reply":"2022-04-27T14:28:09.290041Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Increase the size of the heatmap.\nplt.figure(figsize=(16, 6))\n# Store heatmap object in a variable to easily access it when you want to include more features (such as title).\n# Set the range of values to be displayed on the colormap from -1 to 1, and set the annotation to True to display the correlation values on the heatmap.\nheatmap = sns.heatmap(train.corr(), vmin=-1, vmax=1, annot=True)\n# Give a title to the heatmap. Pad defines the distance of the title from the top of the heatmap.\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:28:09.292302Z","iopub.execute_input":"2022-04-27T14:28:09.292553Z","iopub.status.idle":"2022-04-27T14:28:10.898038Z","shell.execute_reply.started":"2022-04-27T14:28:09.292522Z","shell.execute_reply":"2022-04-27T14:28:10.897180Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Handlling with Missing Values :","metadata":{}},{"cell_type":"code","source":"# Function that print the missing Values's percent of each column\ndef percent_missing_values(df) :\n    percent_missing = df.isnull().sum() * 100 / len(df)\n    missing_value_df = pd.DataFrame({'column_name': df.columns,\n                                 'percent_missing': percent_missing})\n    return missing_value_df.percent_missing.sort_values( ascending = False)\npercent_missing_values(train) , percent_missing_values(test)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:28:17.899733Z","iopub.execute_input":"2022-04-27T14:28:17.900029Z","iopub.status.idle":"2022-04-27T14:28:17.918233Z","shell.execute_reply.started":"2022-04-27T14:28:17.899993Z","shell.execute_reply":"2022-04-27T14:28:17.917275Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"mean_list = ['song_duration_ms' ,'liveness' ,'danceability', 'acousticness' ,'instrumentalness' ,'energy' , 'loudness']\nfor i in mean_list : \n    train.loc[(train[i].isna() == True) , i] = train[i].mean() #Train Data\n    test.loc[(test[i].isna()   == True) , i] = train[i].mean() #Test Data","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:28:18.578697Z","iopub.execute_input":"2022-04-27T14:28:18.579287Z","iopub.status.idle":"2022-04-27T14:28:18.599507Z","shell.execute_reply.started":"2022-04-27T14:28:18.579245Z","shell.execute_reply":"2022-04-27T14:28:18.598883Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train.loc[(train['key'].isna() == True) , 'key'] = 0 #Train Data\ntest.loc[(test['key'].isna()   == True) , 'key'] = 0 #Test Data","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:28:19.332351Z","iopub.execute_input":"2022-04-27T14:28:19.332790Z","iopub.status.idle":"2022-04-27T14:28:19.339824Z","shell.execute_reply.started":"2022-04-27T14:28:19.332748Z","shell.execute_reply":"2022-04-27T14:28:19.339039Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"X_train = train.iloc[:, 1:14 ].values\ny_train = train.song_popularity\n\nX_test = test.iloc[:, 1:14 ].values\n\nX_train.shape , y_train.shape , X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:28:19.992441Z","iopub.execute_input":"2022-04-27T14:28:19.992863Z","iopub.status.idle":"2022-04-27T14:28:20.003682Z","shell.execute_reply.started":"2022-04-27T14:28:19.992832Z","shell.execute_reply":"2022-04-27T14:28:20.003031Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom imblearn.ensemble import BalancedRandomForestClassifier\n\nfrom sklearn.ensemble import VotingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom numpy import mean\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.ensemble import BaggingClassifier\nfrom imblearn.ensemble import BalancedBaggingClassifier\n\n\n# Best: 0.635508 using {'class_weight': None, 'max_depth': 10, 'max_features': 'auto', 'n_estimators': 300}\n# 0.628425 (0.002461) with: {'class_weight': 'balanced', 'max_depth': 30, 'max_features': 'auto', 'n_estimators': 100}\n\n\n# model_RF = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n\n# model   = RandomForestClassifier(class_weight='balanced_subsample',max_depth= 10, max_features= 'auto', n_estimators=500, random_state=1) #Best Param & Best Score 500>300\n# model_LR   = LogisticRegression()\n# model_XGB  = XGBClassifier()\n# model_SVC  = SVC(probability=True)\n\nmodel   = BalancedRandomForestClassifier(max_depth= 10, max_features= 'auto', n_estimators=500, random_state=1) #Best Param & Best Score 500>300\n\n\n# # Voting Classifiers : \n# model = VotingClassifier(\n# estimators=[('lr', model_LR), ('rf', model_RF), ('xgb', model_XGB), ('svc', model_SVC)], voting='soft') #\n# model.fit(X_train, y_train)\n\n \n    \n# define model\n# model = BalancedBaggingClassifier(DecisionTreeClassifier(), n_estimators=500,max_samples=100, bootstrap=True, n_jobs=-1,\n#                                   sampling_strategy = 0.7 ) \n# define evaluation procedure\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n# evaluate model\nscores = cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n# summarize performance\nprint('Mean ROC AUC: %.3f' % mean(scores))       \n\n\n# unique, counts = np.unique(song_popularity, return_counts=True)\n# dict(zip(unique, counts))","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:28:21.231583Z","iopub.execute_input":"2022-04-27T14:28:21.231908Z","iopub.status.idle":"2022-04-27T14:35:04.831426Z","shell.execute_reply.started":"2022-04-27T14:28:21.231872Z","shell.execute_reply":"2022-04-27T14:35:04.830369Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#Scores : \n# AUC : 0.571   RF(n=500)  >>  RF(n=500) With Weight 0.59538 \n# AUC : 0.572   BalancedRandomForestClassifier \n\n# AUC : 0.561   BalancedBaggingClassifier : Majority     \n# AUC : BalancedBaggingClassifier : (Strategy=0.7) >> Cost A lot of Time    ","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:35:04.834256Z","iopub.execute_input":"2022-04-27T14:35:04.834568Z","iopub.status.idle":"2022-04-27T14:35:04.839326Z","shell.execute_reply.started":"2022-04-27T14:35:04.834525Z","shell.execute_reply":"2022-04-27T14:35:04.838315Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"## model_RF = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1) \nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test) \nsong_popularity = predictions\npredict_proba = model.predict_proba(X_test)\n\noutput = pd.DataFrame({'id': test.id, 'song_popularity': predict_proba[:,1]})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2022-04-27T14:35:04.840771Z","iopub.execute_input":"2022-04-27T14:35:04.841190Z","iopub.status.idle":"2022-04-27T14:35:45.003869Z","shell.execute_reply.started":"2022-04-27T14:35:04.841144Z","shell.execute_reply":"2022-04-27T14:35:45.002675Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.model_selection import GridSearchCV\n# from sklearn.model_selection import RepeatedStratifiedKFold\n\n# model = RandomForestClassifier()\n\n\n# cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n\n\n# model_RF   = RandomForestClassifier(max_depth= 10, max_features= 'auto', n_estimators=300, random_state=1) #Best Param\n# param_grid = [\n#   {     'class_weight' :['balanced', None ], \n#         'n_estimators' : [10,100,300],\n#         'max_depth' : [10,20,30],\n#         'max_features' : ['auto',None],\n#   } ]\n\n# grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='accuracy' , verbose = 4)\n# grid_result = grid_search.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-25T08:02:48.558506Z","iopub.execute_input":"2022-03-25T08:02:48.559005Z","iopub.status.idle":"2022-03-25T08:02:48.563847Z","shell.execute_reply.started":"2022-03-25T08:02:48.558964Z","shell.execute_reply":"2022-03-25T08:02:48.563082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize results\n# Best: 0.635508 using {'class_weight': None, 'max_depth': 10, 'max_features': 'auto', 'n_estimators': 300}\n# 0.628425 (0.002461) with: {'class_weight': 'balanced', 'max_depth': 30, 'max_features': 'auto', 'n_estimators': 100}\n\n\n\n# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n# means = grid_result.cv_results_['mean_test_score']\n# stds = grid_result.cv_results_['std_test_score']\n# params = grid_result.cv_results_['params']\n# for mean, stdev, param in zip(means, stds, params):\n#     print(\"%f (%f) with: %r\" % (mean, stdev, param))","metadata":{"execution":{"iopub.status.busy":"2022-03-25T08:02:48.56498Z","iopub.execute_input":"2022-03-25T08:02:48.56563Z","iopub.status.idle":"2022-03-25T08:02:48.590699Z","shell.execute_reply.started":"2022-03-25T08:02:48.565587Z","shell.execute_reply":"2022-03-25T08:02:48.589229Z"},"trusted":true},"execution_count":null,"outputs":[]}]}